{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Tree Canopy - Part 1 (LiDAR Extractor)\n",
    "## When new LiDAR data is available, this script scrapes the neccesary LiDAR files from TxGIO, processes them into a polygon shapefile, and is saved into a newly created GDB. After running this script, you will need to manually QA/QC the final shapefile to check for accuracy and edit as needed. After QA/QC is complete, you can run Part 2.\n",
    "## BEFORE YOU BEGIN\n",
    " 1. Download the ETJ, City Layer, CHHD Layers from sharepoint\n",
    " 2. Import the data into ArcGIS Pro (ensure its in your contents pane)\n",
    " 3. Download the LiDAR Index from TxGIO for the dataset you are going to use\n",
    " 4. Find the find the cities that are completely within the available LiDAR Data. \n",
    " 5. Export these cities to a new shapefile and save it to a GDB\n",
    " 6. The ONLY THING you need to do are these steps and define the variables below, ensuring your file and folder names are where you want them to go. Change the base_url to the S3 link provided on the TxGIO webiste, all the way until the lpc/. (e.g. r'https://tnris-data-warehouse.s3.us-east-1.amazonaws.com/LCD/collection/stratmap-2023-35cm-50cm-elpaso-clearfork-brazos/lpc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT CHANGE THESE\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"80%\"\n",
    "city_names_field = 'Name10'\n",
    "\n",
    "#CHANGE THESE\n",
    "base_url = r'https://tnris-data-warehouse.s3.us-east-1.amazonaws.com/LCD/collection/stratmap-2021-28cm-50cm-bexar-travis/lpc/'\n",
    "workspace = r'D:\\ArcGIS_Projects\\UTC\\UTC'\n",
    "#CHANGE THESE ALSO. USE THE DISPLAY NAME POINTING TO THE SHAPEFILE. \n",
    "#DO NOT USE THE FULL PATH POINTING TO GDB, OTHERWISE THE CODE WILL NOT WORK\n",
    "ETJ = 'Buda_ETJ'\n",
    "lidar_layer = 'Lidar_2021_2023_Files'\n",
    "\n",
    "\n",
    "#DONT CHANGE THESE\n",
    "qa_qc_gdb_name = f\"Polygons_from_{ETJ}\"\n",
    "qa_qc_gdb_path = os.path.join(workspace, f'{qa_qc_gdb_name}.gdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_names(etj_layer, city_field):\n",
    "    city_names = []\n",
    "    with arcpy.da.SearchCursor(etj_layer, city_field) as cursor:\n",
    "        for row in cursor:\n",
    "            city_names.append(row[0])\n",
    "    return city_names\n",
    "\n",
    "def update_city_names(etj_layer, city_field):\n",
    "    with arcpy.da.UpdateCursor(etj_layer, [city_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            row[0] = row[0].replace(\" \", \"\")\n",
    "            cursor.updateRow(row)\n",
    "    print(f\"Updated city names in {etj_layer}\")\n",
    "    \n",
    "def get_ninth_column_name(layer):\n",
    "    fields = arcpy.ListFields(layer)\n",
    "    if len(fields) >= 9:\n",
    "        return fields[8].name\n",
    "    else:\n",
    "        raise ValueError(\"The layer does not have at least 9 columns.\")\n",
    "\n",
    "def download_and_convert_lidar_files(city, lidar_layer, base_url, folder_path):\n",
    "    file_list = []\n",
    "    with arcpy.da.SearchCursor(lidar_layer, 'tilename') as cursor:\n",
    "        for row in cursor:\n",
    "            file_list.append(f\"{row[0].lower()}.laz\")\n",
    "    print(f\"{city} has {len(file_list)} laz files\")\n",
    "    \n",
    "    for count, file_name in enumerate(file_list, start=1):\n",
    "        local_filename = os.path.join(folder_path, file_name)\n",
    "        full_url = base_url + file_name\n",
    "        print(full_url)\n",
    "    \n",
    "        if os.path.exists(local_filename):\n",
    "            print(f\"File {file_name} already exists, skipping download.\")\n",
    "        else:\n",
    "            try:\n",
    "                with requests.get(full_url, stream=True) as r:\n",
    "                    r.raise_for_status()\n",
    "                    with open(local_filename, 'wb') as f:\n",
    "                        for chunk in r.iter_content(chunk_size=8192):\n",
    "                            f.write(chunk)\n",
    "                arcpy.conversion.ConvertLas(local_filename, folder_path)\n",
    "                print(f\"{count} / {len(file_list)} downloaded and converted to LAS\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {file_name}: {e}\")\n",
    "\n",
    "def process_lidar_files(city, folder_path, workspace):\n",
    "    las_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.las')]\n",
    "    lasd = arcpy.management.CreateLasDataset(las_files, os.path.join(folder_path, f'{city}.lasd'))\n",
    "    \n",
    "    filtered_lasd = arcpy.management.MakeLasDatasetLayer(lasd, f'{city}_FilteredLASD', 5, [\"FIRST_OF_MANY\", \"SINGLE\", 1])\n",
    "    \n",
    "    lasd_raster = arcpy.conversion.LasDatasetToRaster(filtered_lasd, f'{city}_LASD_to_Raster.tif', 'ELEVATION', 'BINNING MAXIMUM SIMPLE', 'INTEGER', 'CELLSIZE', 1, 1)\n",
    "    \n",
    "    min_value = arcpy.GetRasterProperties_management(lasd_raster, \"MINIMUM\").getOutput(0)\n",
    "    max_value = arcpy.GetRasterProperties_management(lasd_raster, \"MAXIMUM\").getOutput(0)\n",
    "    print(f\"Min value: {min_value}, Max value: {max_value}\")\n",
    "    \n",
    "    remap_range = arcpy.sa.RemapRange([[min_value, max_value, 1]])\n",
    "    reclassed_raster = arcpy.sa.Reclassify(lasd_raster, \"VALUE\", remap_range)\n",
    "    reclassed_raster.save(f'{city}_reclassed.tif')\n",
    "    \n",
    "    raster_to_polygon_path = f\"{city}_Raster2Polygon\"\n",
    "    arcpy.conversion.RasterToPolygon(reclassed_raster, raster_to_polygon_path)\n",
    "    \n",
    "    \n",
    "    arcpy.management.AddFields(raster_to_polygon_path, [['area', 'FLOAT'], ['perimeter', 'FLOAT'], ['PeriArea', 'FLOAT']])\n",
    "    arcpy.management.CalculateGeometryAttributes(raster_to_polygon_path, [['area', 'AREA_GEODESIC']], 'METERS', 'SQUARE_METERS')\n",
    "    arcpy.management.CalculateGeometryAttributes(raster_to_polygon_path, [['perimeter', 'PERIMETER_LENGTH_GEODESIC']], 'METERS', 'SQUARE_METERS')\n",
    "    arcpy.management.CalculateField(raster_to_polygon_path, 'PeriArea', '!perimeter! / !area!')\n",
    "    \n",
    "    arcpy.SelectLayerByAttribute_management(raster_to_polygon_path,'NEW_SELECTION', 'PeriArea > 1.3')\n",
    "    arcpy.DeleteFeatures_management(raster_to_polygon_path)\n",
    "    arcpy.SelectLayerByAttribute_management(raster_to_polygon_path,'CLEAR_SELECTION')\n",
    "    \n",
    "    union = f'{city}_Union'\n",
    "    arcpy.analysis.Union([raster_to_polygon_path, raster_to_polygon_path], union, 'ALL', \"\", \"NO_GAPS\")\n",
    "    arcpy.management.AddField(union, 'area2', 'FLOAT')\n",
    "    arcpy.management.CalculateGeometryAttributes(union, [['area2', 'AREA_GEODESIC']], 'METERS', 'SQUARE_METERS')\n",
    "    \n",
    "    ninth_column_name = get_ninth_column_name(union)\n",
    "    arcpy.management.SelectLayerByAttribute(union, \"NEW_SELECTION\", f\"area2 > 7 AND {ninth_column_name} = -1\", None)\n",
    "    arcpy.DeleteFeatures_management(union)\n",
    "    \n",
    "    arcpy.management.SelectLayerByAttribute(union, \"NEW_SELECTION\", f\"area2 < 5\", None)\n",
    "    arcpy.DeleteFeatures_management(union)\n",
    "    \n",
    "    merge = f'{city}'\n",
    "    arcpy.management.Merge(union, merge)\n",
    "    \n",
    "    \n",
    "    \n",
    "    output_fc = os.path.join(qa_qc_gdb_path, merge)\n",
    "    arcpy.management.CopyFeatures(merge, output_fc)\n",
    "    \n",
    "    print(f\"Processed lidar files for {city}\")\n",
    "\n",
    "\n",
    "def cleanup_las_files(directory):\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.las') or file_name.endswith('.laz'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\")\n",
    "\n",
    "    \n",
    "def main():\n",
    "    update_city_names(ETJ, city_names_field)\n",
    "    city_names = get_city_names(ETJ, city_names_field)\n",
    "    arcpy.CreateFileGDB_management(workspace, qa_qc_gdb_name)\n",
    "    print(city_names)\n",
    "    for city in city_names:\n",
    "        temp_dir = arcpy.env.scratchFolder\n",
    "        folder_path = arcpy.CreateFolder_management(temp_dir, city).getOutput(0)\n",
    "        arcpy.env.workspace = folder_path\n",
    "        \n",
    "        arcpy.management.SelectLayerByAttribute(ETJ, \"NEW_SELECTION\", f'\"Name10\" = \\'{city}\\'')\n",
    "        arcpy.management.SelectLayerByLocation(lidar_layer, 'INTERSECT', ETJ)\n",
    "        \n",
    "        download_and_convert_lidar_files(city, lidar_layer, base_url, folder_path)\n",
    "        process_lidar_files(city, folder_path, workspace)\n",
    "        \n",
    "        arcpy.management.SelectLayerByAttribute(ETJ, \"CLEAR_SELECTION\")\n",
    "        arcpy.management.SelectLayerByAttribute(lidar_layer, \"CLEAR_SELECTION\")\n",
    "        \n",
    "        cleanup_las_files(folder_path)\n",
    "        \n",
    "        print(f\"Completed processing for {city}\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
